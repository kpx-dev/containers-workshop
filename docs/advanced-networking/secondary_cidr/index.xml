<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Using Secondary CIDRs with EKS on Amazon Chatbot Workshop</title>
    <link>/advanced-networking/secondary_cidr/</link>
    <description>Recent content in Using Secondary CIDRs with EKS on Amazon Chatbot Workshop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Feb 2019 00:35:29 -0500</lastBuildDate>

	<atom:link href="/advanced-networking/secondary_cidr/index.xml" rel="self" type="application/rss+xml" />


    <item>
      <title>Prerequisites</title>
      <link>/advanced-networking/secondary_cidr/prerequisites/</link>
      <pubDate>Fri, 08 Feb 2019 00:35:29 -0500</pubDate>

      <guid>/advanced-networking/secondary_cidr/prerequisites/</guid>
      <description>Before we configure EKS, we need to enable secondary CIDR blocks in your VPC and make sure they have proper tags and route table configurations
Add secondary CIDRs to your VPC There are restrictions on the range of secondary CIDRs you can use to extend your VPC. For more info, see IPv4 CIDR Block Association Restrictions
 You can use below commands to add 100.64.0.0/16 to your EKS cluster VPC.</description>
    </item>

    <item>
      <title>Configure CNI</title>
      <link>/advanced-networking/secondary_cidr/configure-cni/</link>
      <pubDate>Wed, 13 Feb 2019 01:12:49 -0500</pubDate>

      <guid>/advanced-networking/secondary_cidr/configure-cni/</guid>
      <description>Before we start making changes to VPC CNI, let&amp;rsquo;s make sure we are using latest CNI version
Run this command to find CNI version
kubectl describe daemonset aws-node --namespace kube-system | grep Image | cut -d &amp;quot;/&amp;quot; -f 2  Here is a sample response
amazon-k8s-cni:1.4.1  Upgrade version to 1.3 if you have an older version
kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/master/config/v1.3/aws-k8s-cni.yaml  Wait till all the pods are recycled. You can check the status of pods by using this command</description>
    </item>

    <item>
      <title>Create CRDs</title>
      <link>/advanced-networking/secondary_cidr/eniconfig_crd/</link>
      <pubDate>Sat, 02 Mar 2019 12:47:43 -0500</pubDate>

      <guid>/advanced-networking/secondary_cidr/eniconfig_crd/</guid>
      <description>Create custom resources for ENIConfig CRD As next step, we will add custom resources to ENIConfig custom resource definition (CRD). CRD&amp;rsquo;s are extensions of Kubernetes API that stores collection of API objects of certain kind. In this case, we will store VPC Subnet and SecurityGroup configuration information in these CRD&amp;rsquo;s so that Worker nodes can access them to configure VPC CNI plugin.
You should have ENIConfig CRD already installed with latest CNI version (1.</description>
    </item>

    <item>
      <title>Test Networking</title>
      <link>/advanced-networking/secondary_cidr/test_networking/</link>
      <pubDate>Sat, 02 Mar 2019 15:18:32 -0500</pubDate>

      <guid>/advanced-networking/secondary_cidr/test_networking/</guid>
      <description>Launch pods into Secondary CIDR network Let&amp;rsquo;s launch few pods and test networking
kubectl run nginx --image=nginx kubectl scale --replicas=3 deployments/nginx kubectl expose deployment/nginx --type=NodePort --port 80 kubectl get pods -o wide  NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE nginx-64f497f8fd-k962k 1/1 Running 0 40m 100.64.6.147 ip-192-168-52-113.us-east-2.compute.internal &amp;lt;none&amp;gt; nginx-64f497f8fd-lkslh 1/1 Running 0 40m 100.64.53.10 ip-192-168-74-125.us-east-2.compute.internal &amp;lt;none&amp;gt; nginx-64f497f8fd-sgz6f 1/1 Running 0 40m 100.64.80.186 ip-192-168-26-65.us-east-2.compute.internal &amp;lt;none&amp;gt;  You can use busybox pod and ping pods within same host or across hosts using IP address</description>
    </item>

    <item>
      <title>Cleanup</title>
      <link>/advanced-networking/secondary_cidr/cleanup/</link>
      <pubDate>Sat, 02 Mar 2019 16:47:38 -0500</pubDate>

      <guid>/advanced-networking/secondary_cidr/cleanup/</guid>
      <description>Let&amp;rsquo;s cleanup this tutorial
kubectl delete deployments --all  Edit aws-node configmap and comment AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG and its value
kubectl edit daemonset -n kube-system aws-node  ... spec: containers: - env: #- name: AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG # value: &amp;quot;true&amp;quot; - name: AWS_VPC_K8S_CNI_LOGLEVEL value: DEBUG - name: MY_NODE_NAME ...  Delete custom resource objects from ENIConfig CRD
kubectl delete eniconfig/group1-pod-netconfig kubectl delete eniconfig/group2-pod-netconfig kubectl delete eniconfig/group3-pod-netconfig  Terminate EC2 instances so that fresh instances are launched with default CNI configuration</description>
    </item>

  </channel>
</rss>
